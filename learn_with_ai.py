# -*- coding: utf-8 -*-
"""learn-with-ai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19qhrExYZkiiQD8nHZDPaiPyCyXNMpOsF

YouTube has educational content on pretty much any topic, from academic subjects like math and programming to hands-on projects, tutorials, and preparation for professional certifications.

But as a learning tool, YouTube isn't perfect. Some videos have too many ads and sponsorship interruptions, some are slowed down by non-essential information, while others require viewers to pause frequently just to follow the steps.

Imagine if we could get a concise video summary, review it to determine whether it's worth watching, extract step-by-step guidance so we could easily follow along, and at the end, generate a quiz to test our understanding. Wouldn't that be awesome?

In this tutorial, we will be doing exactly that!
We will use open-source ML models from Hugging Face, and OpenAI's ChatGPT APIs.
We should also be able to apply these steps to other use cases by selecting different ML models or adjusting ChatGPT prompts.
"""

#OPENAIKEY = User's OpenAI API Key. Get an API Key here: https://platform.openai.com/settings/organization/api-keys

"""## Let us first use pip to install all the packages required to complete this tutorial."""

#installing libraries
!pip install youtube_transcript_api
!pip install transformers
!pip install openai

"""## Next, let's import all the necessary dependencies."""

#importing dependencies
import re
import os
import openai
import textwrap
from youtube_transcript_api import YouTubeTranscriptApi
from transformers import pipeline, AutoTokenizer
from openai import OpenAI

"""## Now we're ready to work on our first task, which is to obtain a transcript of a YouTube video.
#### One can choose any YouTube video and replace the link in the youtube_url variable. To get a YouTube video url, copy the URL up to the "&" sign.

#### Note: It is recommended that we use a video that is under 30 minutes. This will allow us to complete the tutorial more quickly, as executing commands for longer videos will take more time.

The below code checks if the URL link is valid and then uses the YouTubeTranscriptApi.get_transcript(video_id) method to retrieve the YouTube transcript using the YouTube API. This method provides accurate and official captions associated with the video.
"""

# Specify the YouTube video URL
youtube_url = "https://www.youtube.com/watch?v=b9rs8yzpGYk"

# Extract the video ID from the URL using regular expressions
match = re.search(r"v=([A-Za-z0-9_-]+)", youtube_url)
if match:
    video_id = match.group(1)
else:
    raise ValueError("Invalid YouTube URL")

# Get the transcript from YouTube
transcript = YouTubeTranscriptApi.get_transcript(video_id)

# Concatenate the transcript into a single string
transcript_text = ""
for segment in transcript:
    transcript_text += segment["text"] + " "

print(transcript_text)

"""# Summarizing and Translating a Transcript Using ML Models

#### Now that we have the full transcript of the YouTube video, we can proceed to utilize open-source models for natural language processing tasks, such as summarization, translation, and more. These models will help us to extract valuable insights from the transcript.

#### We will be using the Transformers library from Hugging Face ðŸ¤—. By using pretrained models, we can significantly reduce our compute costs and carbon footprint - and we can save valuable time and resources that would otherwise be required to train a model from scratch.

#### Let's assume that English is not our first language, and we would like to translate the YouTube transcript to Spanish. To achieve this, we can utilize a pretrained machine learning model specifically designed for translation. Translation involves converting a sequence of text from one language to another. It is a task that can be formulated as a sequence-to-sequence problem. By leveraging a pretrained sequence-to-sequence translation model, we can effectively translate the YouTube transcript from English to Spanish.
"""

# Define the maximum sequence length
max_length = 512

# Replace this with your own checkpoint
model_checkpoint = "Helsinki-NLP/opus-mt-en-es"
translator = pipeline("translation", model=model_checkpoint)
# model_checkpoint = "google-t5/t5-small"
# translator = pipeline("translation_es_to_en", model=model_checkpoint,max_length=max_length)


# Split the input text into smaller segments
segments = [transcript_text[i:i+max_length] for i in range(0, len(transcript_text), max_length)]

# Translate each segment and concatenate the results
translated_text = ""
for segment in segments:
    result = translator(segment)
    translated_text += result[0]['translation_text']

print(translated_text)

"""#### Next, we will proceed with summarizing the video using a pretrained model for text summarization. In this case, we will be using the original transcript in English. However, if one choses to continue with the translated transcript, one can replace the 'transcript_text' variable with the 'translated_text' variable that contains the translated text. By applying the summarization model to the transcript, we can generate a concise summary of the video's content."""

# Instantiate the tokenizer and the summarization pipeline
tokenizer = AutoTokenizer.from_pretrained('stevhliu/my_awesome_billsum_model')
summarizer_stevhliu = pipeline("summarization", model='stevhliu/my_awesome_billsum_model', tokenizer=tokenizer)

# Instantiate the tokenizer and the summarization pipeline
tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-cnn')
summarizer_facebook = pipeline("summarization", model='facebook/bart-large-cnn', tokenizer=tokenizer)

# Define chunk size in number of words
chunk_size = 200 # one may need to adjust this value depending on the average length of your words

# Split the text into chunks
words = transcript_text.split()
chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]

"""#### In the below 2 blocks, we will be using 2 different pre-trained models for summarization activity:


1.  stevhliu/my_awesome_billsum_model
2.  facebook/bart-large-cnn

We have already defined the 'Tokenizer' and summarisation pipeline for both of these models earlier.


"""

# Summarize each chunk using stevhliu/my_awesome_billsum_model
summaries = []
for chunk in chunks:
    # Summarize the chunk
    summary = summarizer_stevhliu(chunk, max_length=100, min_length=30, do_sample=False)

    # Extract the summary text
    summary_text = summary[0]['summary_text']

    # Add the summary to our list of summaries
    summaries.append(summary_text)

# Join the summaries back together into a single summary
final_summary_stevhliu = ' '.join(summaries)

# Summarize each chunk using facebook/bart-large-cnn
summaries = []
for chunk in chunks:
    # Summarize the chunk
    summary = summarizer_facebook(chunk, max_length=100, min_length=30, do_sample=False)

    # Extract the summary text
    summary_text = summary[0]['summary_text']

    # Add the summary to our list of summaries
    summaries.append(summary_text)

# Join the summaries back together into a single summary
final_summary_facebook = ' '.join(summaries)

"""#### We can also perform summarization on the translated text"""

# Performing summarization using facebook/bart-large-cnn, on the translated spanish text
# Split the text into chunks
words = translated_text.split()
chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]

# Summarize each chunk
summaries = []
for chunk in chunks:
    # Summarize the chunk
    summary = summarizer_facebook(chunk, max_length=100, min_length=30, do_sample=False)

    # Extract the summary text
    summary_text = summary[0]['summary_text']

    # Add the summary to our list of summaries
    summaries.append(summary_text)

# Join the summaries back together into a single summary
final_summary_facebook_es = ' '.join(summaries)

print(final_summary_stevhliu)

print(final_summary_facebook)

print(final_summary_facebook_es)

"""#### Below we try to translate back the summarized spanish text to english"""

# Translating the spanish summary to english
model_checkpoint = "Helsinki-NLP/opus-mt-es-en"
translator = pipeline("translation", model=model_checkpoint)


# Split the input text into smaller segments
segments = [final_summary_facebook_es[i:i+max_length] for i in range(0, len(final_summary_facebook_es), max_length)]

# Translate each segment and concatenate the results
translated_text = ""
for segment in segments:
    result = translator(segment)
    translated_text += result[0]['translation_text']

print(translated_text)

"""## We were able to get a concise summary of the video's content, excluding any sponsorships, advertisements, or other extraneous information. This enables us to quickly grasp the key points and main ideas from the video without being slowed down by unnecessary details.

## Let us now proceed to the next step, where we will re-generate a summary to compare results from OpenAI vs an open-source model, as well as create a step-by-step tutorial based on the summarized transcript and a quiz to test our understanding and gained knowledge.

# Extracting Steps and Creating a Quiz Using ChatGPT APIs

#### Let's obtain a video summary using the ChatGPT model and compare it to the summary we obtained in the previous step using open-source models.
"""

def split_text_into_chunks(text, max_chunk_size):
    return textwrap.wrap(text, max_chunk_size)

client = OpenAI(api_key=OPENAIKEY)
max_chunk_size = 4000

transcript_chunks = split_text_into_chunks(transcript_text, max_chunk_size)
summaries = ""

for chunk in transcript_chunks:
    response = client.chat.completions.create(
                                              model="gpt-4o-mini",
                                              messages=[
                                                        {"role": "system", "content": "You are a helpful assistant."},
                                                        {"role": "user", "content": f"{chunk}\n\nCreate short concise summary"}
                                                      ],
                                              max_tokens=250,
                                              temperature=0.5
                                            )

    summaries += response.choices[0].message.content.strip() + " "

print("Summary: \n")
print(summaries)

"""## Let's proceed by modifying the prompts and instructing ChatGPT to extract the necessary steps from the video transcript.
#### By doing so, we can generate a step-by-step guide that provides clear instructions for us to follow along. This will help us to have a structured, guided approach while engaging with the video content.
"""

response = client.chat.completions.create(
                                          model="gpt-4o-mini",
                                          messages=[
                                                    {"role": "system", "content": "You are a technical instructor."},
                                                    {"role": "user", "content": transcript_text},
                                                    {"role": "user", "content": "Generate steps to follow from text."},
                                                  ]
                                        )

# The assistant's reply
guide= response.choices[0].message.content

print("Steps:")
print(guide)

"""## Letâ€™s generate a quiz based on the materials covered in the video.
#### The quiz will assess our understanding of the content. You will see a quiz with 10 question generated to test your knowledge. This can be especially helpful if you are preparing for exams. You can modify a prompt to explain the right answers - for example: "Generate 10 quiz questions based on the text with multiple choices and explain why a particular answer is the right one".
"""

response = client.chat.completions.create(
                                          model="gpt-4o-mini",
                                          messages=[
                                                    {"role": "system", "content": "You are a helpful assistant that generates questions."},
                                                    {"role": "user", "content": transcript_text},
                                                    {"role": "user", "content": "Generate 10 quiz questions based on the text with multiple choices."},
                                                  ]
                                        )

# The assistant's reply
quiz_questions = response.choices[0].message.content

print("Quiz Questions:")
print(quiz_questions)